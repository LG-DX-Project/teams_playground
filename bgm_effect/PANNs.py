import os
import sys
import urllib.request
import ssl
import cv2
import numpy as np
import sounddevice as sd
import time
import imageio_ffmpeg as ffmpeg_bin
import subprocess
from PIL import ImageFont, ImageDraw, Image
import torch
import librosa
from contextlib import contextmanager

# ==========================================
# [0] ë¡œê·¸ ì°¨ë‹¨ê¸°
# ==========================================
@contextmanager
def suppress_stderr():
    with open(os.devnull, "w") as devnull:
        old_stderr = sys.stderr
        sys.stderr = devnull
        try:
            try:
                fd_stderr = 2
                fd_dup = os.dup(fd_stderr)
                os.dup2(devnull.fileno(), fd_stderr)
                yield
            except Exception:
                yield
            finally:
                try:
                    os.dup2(fd_dup, fd_stderr)
                    os.close(fd_dup)
                except Exception:
                    pass
        finally:
            sys.stderr = old_stderr

# ==========================================
# [1] ì‹œìŠ¤í…œ ì„¤ì •
# ==========================================
def check_panns_setup():
    ssl._create_default_https_context = ssl._create_unverified_context
    home_dir = os.path.expanduser("~")
    panns_dir = os.path.join(home_dir, "panns_data")
    if not os.path.exists(panns_dir): os.makedirs(panns_dir)
    
    csv_path = os.path.join(panns_dir, "class_labels_indices.csv")
    if not os.path.exists(csv_path): pass 

    model_url = "https://zenodo.org/record/3987831/files/Cnn14_mAP%3D0.431.pth?download=1"
    model_path = os.path.join(panns_dir, "Cnn14_mAP=0.431.pth")
    if not os.path.exists(model_path):
        try: urllib.request.urlretrieve(model_url, model_path)
        except Exception: sys.exit(1)

check_panns_setup()
from panns_inference import AudioTagging

# ==========================================
# [2] ì„¤ì •
# ==========================================
VIDEO_PATH = './outputs/íŽœíŠ¸_video.mp4'
FONT_PATH = "C:/Windows/Fonts/malgun.ttf"
SAMPLE_RATE = 32000
VOLUME_BOOST = 6.0 
ANALYSIS_INTERVAL = 0.1
BGM_HOLD_TIME = 2.0 

device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f">>> ì‚¬ìš© ìž¥ì¹˜: {device}")

with suppress_stderr():
    model = AudioTagging(checkpoint_path=None, device=device)
labels = model.labels

# ==========================================
# [3] ë²ˆì—­ ì‚¬ì „
# ==========================================
translation_dict = {
    # --- [A] ë°°ê²½ìŒì•… ---
    'Dramatic music': 'ì›…ìž¥í•œ ìŒì•…ì´ íë¥¸ë‹¤', 'Film score': 'ì˜í™” ê°™ì€ ì›…ìž¥í•œ ì„ ìœ¨ì´ ê¹”ë¦°ë‹¤',
    'Orchestra': 'ì˜¤ì¼€ìŠ¤íŠ¸ë¼ ì—°ì£¼ê°€ ì‹œìž‘ëœë‹¤', 'Choir': 'ì›…ìž¥í•œ í•©ì°½ ì†Œë¦¬ê°€ ìš¸ë¦°ë‹¤',
    'Soundtrack music': 'ë¹„ìž¥í•œ ìŒì•…ì´ íë¥¸ë‹¤', 'Theme music': 'í…Œë§ˆê³¡ì´ íë¥¸ë‹¤',
    'Symphony': 'ì›…ìž¥í•œ êµí–¥ê³¡ì´ íë¥¸ë‹¤',

    'Sad music': 'ìŠ¬í”ˆ ì„ ìœ¨ì´ íë¥¸ë‹¤', 
    'Lullaby': 'ìž”ìž”í•œ ìžìž¥ê°€ê°€ ë“¤ë¦°ë‹¤', 'Music': 'ìž”ìž”í•œ ë°°ê²½ìŒì•…ì´ íë¥¸ë‹¤', 
    'Background music': 'ë°°ê²½ìŒì•…ì´ ê¹”ë¦°ë‹¤',

    'Happy music': 'ê²½ì¾Œí•œ ìŒì•…ì´ íë¥¸ë‹¤', 'Exciting music': 'ë°•ì§„ê° ë„˜ì¹˜ëŠ” ìŒì•…ì´ íë¥¸ë‹¤',
    'Pop music': 'ì‹ ë‚˜ëŠ” íŒì†¡ì´ ë‚˜ì˜¨ë‹¤', 'Rock music': 'ê°•ë ¬í•œ ë½ ìŒì•…ì´ í„°ì ¸ ë‚˜ì˜¨ë‹¤',
    'Electronic music': 'ì‹ ë‚˜ëŠ” ì „ìžìŒì´ ë“¤ë¦°ë‹¤', 'Hip hop music': 'íž™í•© ë¹„íŠ¸ê°€ íë¥¸ë‹¤',
    'Disco': 'ì‹ ë‚˜ëŠ” ë””ìŠ¤ì½” ìŒì•…ì´ ë‚˜ì˜¨ë‹¤',

    'Scary music': 'ìœ¼ìŠ¤ìŠ¤í•œ ìŒì•…ì´ íë¥¸ë‹¤', 'Suspense': 'ê¸´ìž¥ê° ë„˜ì¹˜ëŠ” ìŒì•…ì´ íë¥¸ë‹¤',

    # --- [B] ì‚¬ëžŒ ì†Œë¦¬ ---
    'Breathing': 'ê±°ì¹œ ìˆ¨ì†Œë¦¬ê°€ ë“¤ë¦°ë‹¤', 'Pant': 'ìˆ¨ì„ í—ë–¡ì¸ë‹¤', 'Gasp': 'ìˆ¨ì„ ë“¤ì´í‚¨ë‹¤',
    'Sigh': 'ê¹Šì€ í•œìˆ¨ì„ ë‚´ì‰°ë‹¤', 'Throat clearing': 'ëª©ì„ ê°€ë‹¤ë“¬ëŠ”ë‹¤',
    'Cough': 'ì½œë¡ê±°ë¦¬ë©° ê¸°ì¹¨ì„ í•œë‹¤', 'Sneeze': 'ìž¬ì±„ê¸°ë¥¼ í•œë‹¤', 
    'Screaming': 'ë¹„ëª… ì†Œë¦¬ê°€ ìš¸ë ¤ í¼ì§„ë‹¤', 'Crying, sobbing': 'ëˆ„êµ°ê°€ íëŠê»´ ìš´ë‹¤', 
    'Laughter': 'ì›ƒìŒ ì†Œë¦¬ê°€ ë“¤ë¦°ë‹¤', 'Footsteps': 'ë°œìžêµ­ ì†Œë¦¬ê°€ ë“¤ë¦°ë‹¤', 
    'Crowd': 'ì‚¬ëžŒë“¤ì´ ì›…ì„±ê±°ë¦°ë‹¤',

    # --- [C] ì „íˆ¬/ì•¡ì…˜ ---
    'Punch': 'ë‘”íƒí•œ ì£¼ë¨¹ ì†Œë¦¬ê°€ ë‚œë‹¤',
    'Slap, smack': 'ì§! (ë•Œë¦¬ëŠ” ì†Œë¦¬)',
    'Clapping': 'ì§! (ë°•ìˆ˜ ì†Œë¦¬)',     
    'Applause': 'ë°•ìˆ˜ ê°ˆì±„ê°€ ìŸì•„ì§„ë‹¤', 
    
    'Thump, thud': 'ì¿µ! í•˜ê³  ë¶€ë”ªížŒë‹¤', 'Fighting': 'ê²©í•œ ëª¸ì‹¸ì›€ ì†Œë¦¬ê°€ ë“¤ë¦°ë‹¤', 
    'Wrestling': 'ì˜·ê¹ƒì´ ìŠ¤ì¹˜ë©° ë’¤ì—‰í‚¨ë‹¤', 'Whoosh, swoosh, swish': 'ë¬´ì–¸ê°€ íœ™ í•˜ê³  ì§€ë‚˜ê°„ë‹¤',
    'Clang': 'ë‚ ì¹´ë¡œìš´ ì¹¼ ë¶€ë”ªížˆëŠ” ì†Œë¦¬ê°€ ë‚œë‹¤',
    'Gunshot, gunfire': 'ì´ì„±ì´ ìš¸ë¦°ë‹¤', 
    'Explosion': 'ê±°ëŒ€í•œ í­ë°œìŒì´ ë“¤ë¦°ë‹¤',
    'Tools': 'ì² ê·¸ëŸ­ê±°ë¦¬ëŠ” ì†Œë¦¬ê°€ ë‚œë‹¤',

    # --- [D] ìœ ë¦¬ ì†Œë¦¬ (ì˜¤ì¸ì‹ ì£¼ì˜) ---
    'Shatter': 'ìœ ë¦¬ê°€ ì™€ìž¥ì°½ ê¹¨ì§„ë‹¤', 
    'Glass': 'ìœ ë¦¬ê°€ ê¹¨ì§€ëŠ” ì†Œë¦¬ê°€ ë‚œë‹¤',

    # --- [E] ìžì—°/ì‚¬ë¬¼ ---
    'Rain': 'ë¹—ì†Œë¦¬ê°€ ë“¤ë¦°ë‹¤', 'Thunder': 'ì²œë‘¥ì´ ì¹œë‹¤', 'Wind': 'ë°”ëžŒì´ ì„¸ì°¨ê²Œ ë¶„ë‹¤', 
    'Water': 'ë¬¼ íë¥´ëŠ” ì†Œë¦¬ê°€ ë“¤ë¦°ë‹¤', 'Fire': 'ë¶ˆì´ íƒ€ì˜¤ë¥´ëŠ” ì†Œë¦¬ê°€ ë‚œë‹¤',
    'Door': 'ë¬¸ì´ ì—´ë¦¬ëŠ” ì†Œë¦¬ê°€ ë‚œë‹¤', 'Knock': 'ëˆ„êµ°ê°€ ë¬¸ì„ ë‘ë“œë¦°ë‹¤'
}

def get_korean_label(english_label):
    return translation_dict.get(english_label, None)

# ==========================================
# [4] í‚¤ì›Œë“œ ë¶„ë¥˜ ë¦¬ìŠ¤íŠ¸
# ==========================================
ALL_MUSIC_KEYS = [
    'Dramatic music', 'Film score', 'Orchestra', 'Choir', 'Soundtrack music', 'Theme music',
    'Sad music', 'Tender music', 'Lullaby', 'Happy music', 'Exciting music', 'Pop music', 
    'Rock music', 'Electronic music', 'Disco', 'Hip hop music', 'Scary music', 'Suspense',
    'Music', 'Background music', 'Musical instrument', 'Plucked string instrument',
    'Piano', 'Guitar', 'Electric guitar', 'Bass guitar', 'Acoustic guitar', 
    'Violin, fiddle', 'Cello', 'Harp', 'Synthesizer', 'Drum kit', 'Drum',
    'Brass instrument', 'Woodwind instrument', 'Percussion', 'Keyboard (musical)'
]

PRIORITY_GENRE_KEYS = [
    'Rock music', 'Pop music', 'Hip hop music', 'Electronic music', 'Disco',
    'Dramatic music', 'Film score', 'Orchestra', 'Soundtrack music',
    'Sad music', 'Tender music', 'Scary music', 'Suspense', 'Happy music', 'Exciting music'
]

# â˜… ëº¨ ë•Œë¦¬ëŠ” ì†Œë¦¬ (ë¯¼ê°ë„ ìµœìƒ)
SLAP_KEYS = ['Slap, smack', 'Clapping', 'Hands'] 

# â˜… ìœ ë¦¬ ì†Œë¦¬ (ë¯¼ê°ë„ ìµœí•˜ - ëº¨ì†Œë¦¬ ì˜¤ì¸ì‹ ë°©ì§€ìš©)
GLASS_KEYS = ['Glass', 'Shatter', 'Breaking']

FIGHT_KEYS = [
    'Thump, thud', 'Punch', 'Wrestling', 'Fighting', 'Grunt', 'Groan',
    'Smash, crash', 'Whack, thwack', 'Whoosh, swoosh, swish', 'Clang', 'Ding', 
    'Metal', 'Explosion', 'Gunshot, gunfire', 
    'Cutlery, silverware', 'Dishes, pots, and pans', 'Tools', 'Hammer', 'Mechanisms'
]

GENERAL_SFX_KEYS = [
    'Breathing', 'Pant', 'Gasp', 'Sigh', 'Throat clearing', 'Cough', 'Sneeze',
    'Screaming', 'Crying, sobbing', 'Laughter', 'Footsteps', 'Applause', 'Cheering', 'Crowd',
    'Rain', 'Thunder', 'Wind', 'Water', 'Fire', 'Door', 'Knock'
]

SFX_KEYS = FIGHT_KEYS + GENERAL_SFX_KEYS + SLAP_KEYS + GLASS_KEYS

IGNORE_LIST = [
    'Metal','Cutlery, silverware','Tender music', 'Cheering',
    'Silence', 'Speech', 'Male speech, man speaking', 'Female speech, woman speaking', 
    'Child speech, kid speaking', 'Conversation', 'Narration, monologue', 'Babbling', 
    'Inside, small room', 'Inside, large room', 'Outside, urban, or man-made', 
    'Static', 'Noise', 'White noise', 'Pink noise', 'Ambience'
]

AMBIGUOUS_SFX = ['Thump, thud', 'Smash, crash', 'Whack, thwack', 'Clang', 'Metal', 'Ding', 'Tools', 'Hammer', 'Mechanisms', 'Scrape', 'Rub', 'Noise']

# ==========================================
# [5] ìœ í‹¸ë¦¬í‹°
# ==========================================
def extract_audio_ffmpeg(v_path, a_path):
    if os.path.exists(a_path): os.remove(a_path)
    cmd = [ffmpeg_bin.get_ffmpeg_exe(), "-i", v_path, "-vn", "-acodec", "pcm_s16le", 
           "-ar", str(SAMPLE_RATE), "-ac", "1", "-y", a_path]
    subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

def put_dual_text(image, bgm_text, sfx_text, frame_width, frame_height):
    img_pil = Image.fromarray(image)
    draw = ImageDraw.Draw(img_pil)
    try: font = ImageFont.truetype(FONT_PATH, max(20, int(frame_width / 35)))
    except: font = ImageFont.load_default()
    
    center_x = frame_width // 2
    bottom_margin = int(frame_height * 0.9) 
    
    if bgm_text:
        text = f"â™ª {bgm_text}"
        bbox = draw.textbbox((0, 0), text, font=font)
        w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]
        x, y = center_x - w // 2, bottom_margin - h - 10
        draw.rectangle([(x-10, y-5), (x+w+10, y+h+5)], fill=(0,0,0,160))
        draw.text((x, y), text, font=font, fill=(100, 255, 255)) 
        bottom_margin = y - 15 

    if sfx_text:
        fight_flags = ['í½', 'ì¿µ', 'ì¾…', 'íƒ•', 'ì´', 'í­ë°œ', 'ì§', 'ë•Œë¦¬ëŠ”']
        if any(k in sfx_text for k in fight_flags): color = (255, 80, 80)
        else: color = (255, 255, 100)
        
        text = f"ðŸ”Š {sfx_text}"
        bbox = draw.textbbox((0, 0), text, font=font)
        w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]
        x, y = center_x - w // 2, bottom_margin - h - 10
        draw.rectangle([(x-10, y-5), (x+w+10, y+h+5)], fill=(0,0,0,160))
        draw.text((x, y), text, font=font, fill=color)

    return np.array(img_pil)

# ==========================================
# [6] ë©”ì¸ ì‹¤í–‰
# ==========================================
def main():
    if not os.path.exists(VIDEO_PATH): 
        print(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {VIDEO_PATH}")
        return

    temp_audio = 'temp_audio_final.wav'
    print("[ì§„í–‰] ì˜¤ë””ì˜¤ ì¶”ì¶œ ì¤‘...")
    extract_audio_ffmpeg(VIDEO_PATH, temp_audio)
    
    audio_origin, _ = librosa.load(temp_audio, sr=SAMPLE_RATE)
    audio_for_ai = audio_origin * VOLUME_BOOST 
    
    cap = cv2.VideoCapture(VIDEO_PATH)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    print("[ì§„í–‰] ìž¬ìƒ ì‹œìž‘ (ì¢…ë£Œ: q)")
    sd.play(audio_origin, SAMPLE_RATE)
    start_time = time.time()

    # ìƒíƒœ ê´€ë¦¬ ë³€ìˆ˜
    current_bgm_display = ""
    current_sfx_display = ""
    last_printed_bgm = "" 
    bgm_last_detected_time = 0 
    last_detected_bgm_text = "" 
    last_pred_time = 0
    prev_rms = 0.0

    with suppress_stderr():
        while cap.isOpened():
            elapsed = time.time() - start_time
            cap.set(cv2.CAP_PROP_POS_MSEC, elapsed * 1000)
            ret, frame = cap.read()
            if not ret: break

            if elapsed - last_pred_time > ANALYSIS_INTERVAL:
                idx = int(elapsed * SAMPLE_RATE)
                short_window = int(SAMPLE_RATE * 0.3) 
                start_idx = max(0, idx - short_window)
                
                waveform_seg = audio_for_ai[start_idx:idx]
                
                if len(waveform_seg) > 500:
                    rms = np.sqrt(np.mean(waveform_seg**2))
                    is_impact = (rms > prev_rms * 1.5) or (rms > 0.1)
                    prev_rms = rms

                    target_len = SAMPLE_RATE
                    repeats = (target_len // len(waveform_seg)) + 1
                    tiled_seg = np.tile(waveform_seg, repeats)[:target_len]
                    
                    with torch.no_grad():
                        output, _ = model.inference(tiled_seg[None, :])
                    
                    scores = output[0]
                    top_idx = np.argsort(scores)[::-1] 
                    
                    bgm_candidates = []
                    sfx_candidates_raw = []

                    # ìƒìœ„ 5ê°œ íƒìƒ‰
                    for i in top_idx[:5]:
                        label = labels[i]
                        score = scores[i]
                        
                        if label in IGNORE_LIST: continue
                        korean = get_korean_label(label)
                        if not korean: continue

                        # BGM
                        if label in ALL_MUSIC_KEYS:
                            min_score = 0.6 if label not in PRIORITY_GENRE_KEYS and label != 'Music' else 0.05
                            if score > min_score:
                                bgm_candidates.append((label, score, korean))
                        
                        # SFX
                        elif label in SFX_KEYS:
                            # â˜… [í•µì‹¬] ìž„ê³„ê°’ ì°¨ë³„í™” â˜…
                            if label in GLASS_KEYS:
                                if score > 0.7:
                                    # ì§„ì§œ ìœ ë¦¬ ì†Œë¦¬
                                    thr = 0.7
                                elif is_impact and score > 0.15:
                                    # ìœ ë¦¬ ì ìˆ˜ëŠ” ë‚®ì§€ë§Œ ì¶©ê²©ì´ ìžˆë‹¤ -> ëº¨ ì†Œë¦¬ë¡œ ê°•ì œ ë³€í™˜
                                    korean = 'ì§! (ë•Œë¦¬ëŠ” ì†Œë¦¬)' # ë¼ë²¨ ë°”ê¿”ì¹˜ê¸°
                                    thr = 0.15
                                else:
                                    thr = 0.7 # ë¬´ì‹œ
                            
                            elif label in SLAP_KEYS:
                                thr = 0.05 if is_impact else 0.25
                            elif label == 'Sneeze':
                                thr = 0.9
                            elif label == 'Gunshot, gunfire':
                                thr = 0.7 
                            elif label in FIGHT_KEYS and is_impact:
                                thr = 0.05
                            else:
                                thr = 0.3

                            if score > thr:
                                sfx_candidates_raw.append((label, korean))

                    # BGM ì„ ì •
                    temp_bgm = ""
                    if bgm_candidates:
                        genre_matches = [x for x in bgm_candidates if x[0] in PRIORITY_GENRE_KEYS]
                        if genre_matches:
                            genre_matches.sort(key=lambda x: x[1], reverse=True)
                            temp_bgm = genre_matches[0][2]
                        else:
                            bgm_candidates.sort(key=lambda x: x[1], reverse=True)
                            temp_bgm = bgm_candidates[0][2]
                        
                        bgm_last_detected_time = elapsed
                        last_detected_bgm_text = temp_bgm
                    else:
                        if elapsed - bgm_last_detected_time < BGM_HOLD_TIME:
                            temp_bgm = last_detected_bgm_text
                        else:
                            temp_bgm = ""

                    # SFX ì„ ì •
                    is_music_playing = (temp_bgm != "")
                    valid_sfx_list = []
                    for label_eng, label_ko in sfx_candidates_raw:
                        if is_music_playing and label_eng in AMBIGUOUS_SFX: continue
                        valid_sfx_list.append(label_ko)
                    
                    final_sfx = valid_sfx_list[0] if valid_sfx_list else ""

                    current_bgm_display = temp_bgm
                    current_sfx_display = final_sfx
                    
                    # ì½˜ì†” ì¶œë ¥ (ì¤‘ë³µ ì œê±°)
                    should_print = False
                    if temp_bgm != last_printed_bgm:
                        should_print = True
                        last_printed_bgm = temp_bgm
                    if final_sfx:
                        should_print = True

                    if should_print:
                        log_msg = f"[{elapsed:.1f}s] "
                        if temp_bgm: log_msg += f"BGM: {temp_bgm} "
                        if final_sfx: log_msg += f"| SFX: {final_sfx}"
                        if log_msg.strip() != f"[{elapsed:.1f}s]":
                            sys.stdout.write(log_msg + "\n")

                    last_pred_time = elapsed

            frame = put_dual_text(frame, current_bgm_display, current_sfx_display, width, height)
            cv2.imshow('Final Corrected Slap Detector', frame)
            if cv2.waitKey(1) & 0xFF == ord('q'): break

    sd.stop()
    cap.release()
    cv2.destroyAllWindows()
    if os.path.exists(temp_audio): os.remove(temp_audio)

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        sys.stdout.write(f"Error: {e}\n")
        sd.stop()
        cv2.destroyAllWindows()
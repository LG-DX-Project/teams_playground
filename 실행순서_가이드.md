# 텍스트 마이닝 분석 실행 순서 가이드

## 📋 전체 분석 흐름

일반적인 텍스트 마이닝 분석 순서에 따라 다음 단계로 진행합니다:

```
1. 형태소 분석 및 TF-IDF 분석
   ↓
2. 덴드로그램 시각화 (계층적 클러스터링)
   ↓
3. BERTopic 클러스터링 (토픽 모델링)
   ↓
4. 감정분석 (KcELECTRA)
   ↓
5. CAM 기회영역 시각화
```

---

## 🔢 실행 순서별 상세 설명

### 1단계: `1_형태소분석_TFIDF.py`
**목적**: 텍스트 전처리 및 벡터화

**수행 작업**:
- CSV 파일 로드
- 형태소 분석 (명사, 동사, 형용사 추출)
- TF-IDF 벡터화
- 단어 빈도 분석

**출력 파일**:
- `형태소분석_결과.csv`: 형태소 분석 결과
- `TFIDF_상위특성.csv`: 상위 TF-IDF 특성
- `단어빈도.csv`: 단어 빈도 분석
- `tfidf_matrix.pkl`: TF-IDF 행렬 (2단계에서 사용)

**실행 명령**:
```bash
python 1_형태소분석_TFIDF.py --input data.csv --text_column content
```

---

### 2단계: `2_덴드로그램_시각화.py`
**목적**: 계층적 클러스터링 시각화로 데이터 구조 파악

**수행 작업**:
- 1단계에서 생성한 TF-IDF 행렬 로드
- 계층적 클러스터링 (Ward linkage)
- 덴드로그램 생성 및 저장

**출력 파일**:
- `덴드로그램.png`: 계층적 클러스터링 덴드로그램

**실행 명령**:
```bash
python 2_덴드로그램_시각화.py --input data.csv --tfidf_pkl output/tfidf_matrix.pkl
```

**참고**: 
- 문서 수가 많으면 `--max_docs` 옵션으로 샘플링 가능
- 덴드로그램은 데이터의 계층적 구조를 시각화하여 클러스터 수 결정에 도움

---

### 3단계: `3_BERTopic_클러스터링.py`
**목적**: 문서 임베딩 기반 토픽 자동 발견

**수행 작업**:
- SentenceTransformer로 문서 임베딩 생성
- UMAP으로 차원 축소
- HDBSCAN으로 토픽 클러스터링
- 토픽별 대표 키워드 추출

**출력 파일**:
- `문서별_토픽할당.csv`: 각 문서에 할당된 토픽 ID와 확률
- `토픽요약정보.csv`: 토픽별 문서 수, 대표 키워드

**실행 명령**:
```bash
python 3_BERTopic_클러스터링.py --input data.csv --text_column content
```

**주요 특징**:
- 토픽 수를 자동으로 결정 (HDBSCAN)
- 노이즈 문서는 -1로 표시
- GPU 없이도 실행 가능 (CPU 모드)

---

### 4단계: `4_감정분석.py`
**목적**: KcELECTRA 모델로 감정 분류

**수행 작업**:
- KcELECTRA 모델 로드
- 각 문서의 감정 레이블 예측 (0: 부정, 1: 긍정)
- 감정 확률 계산

**출력 파일**:
- `감정분석_결과.csv`: 문서별 감정 레이블 및 확률

**실행 명령**:
```bash
python 4_감정분석.py --input data.csv --text_column content --model beomi/KcELECTRA-base-v2022
```

**모델 확인**:
- `beomi/KcELECTRA-base-v2022`는 한국어 ELECTRA 모델로 감정분석에 적합합니다.
- HuggingFace에서 확인: https://huggingface.co/beomi/KcELECTRA-base-v2022
- 이 모델은 시퀀스 분류(Sequence Classification) 태스크에 사용됩니다.

---

### 5단계: `5_CAM_기회영역_시각화.py`
**목적**: Importance와 Satisfaction 기반 기회영역 분석

**수행 작업**:
- 토픽별 Importance 계산 (빈도 기반)
- Satisfaction 점수 계산 (감정분석 결과 기반)
- Opportunity 점수 계산
- 기회영역 액션맵 시각화

**출력 파일**:
- `기회영역_분석.csv`: Action별 Importance, Satisfaction, Opportunity 점수
- `기회영역_분석_plot.png`: 기회영역 액션맵 (scatter plot)

**실행 명령**:
```bash
python 5_CAM_기회영역_시각화.py --topics_csv output/문서별_토픽할당.csv --sentiment_csv output/감정분석_결과.csv
```

---

### 6단계: `6_통합_파이프라인.py` (선택적)
**목적**: 1~5단계를 한 번에 실행

**실행 명령**:
```bash
python 6_통합_파이프라인.py --input data.csv --text_column content
```

**참고**: 개별 단계를 따로 실행하는 것을 권장합니다. 각 단계의 결과를 확인하며 진행할 수 있습니다.

---

## 🔄 전체 로직 흐름

```
[입력] CSV 파일 (id, content 컬럼)
    ↓
[1단계] 형태소 분석 + TF-IDF
    ├─ 형태소 분석: 텍스트 → 키워드 추출
    ├─ TF-IDF: 키워드 → 벡터화
    └─ 출력: tfidf_matrix.pkl
    ↓
[2단계] 덴드로그램 시각화
    ├─ TF-IDF 행렬 로드
    ├─ 계층적 클러스터링 (Ward)
    └─ 출력: 덴드로그램.png
    ↓
[3단계] BERTopic 클러스터링
    ├─ 원본 텍스트 → SentenceTransformer 임베딩
    ├─ UMAP 차원 축소
    ├─ HDBSCAN 클러스터링
    └─ 출력: 문서별_토픽할당.csv, 토픽요약정보.csv
    ↓
[4단계] 감정분석
    ├─ 원본 텍스트 → KcELECTRA 모델
    ├─ 감정 레이블 예측 (0/1)
    └─ 출력: 감정분석_결과.csv
    ↓
[5단계] CAM 기회영역 시각화
    ├─ 토픽 할당 + 감정분석 결과 병합
    ├─ Importance 계산 (토픽 빈도)
    ├─ Satisfaction 계산 (감정 점수)
    ├─ Opportunity 계산
    └─ 출력: 기회영역_분석.csv, 기회영역_분석_plot.png
```

---

## 📊 각 단계의 역할

### 1단계: 형태소 분석 및 TF-IDF
- **역할**: 텍스트를 분석 가능한 형태로 변환
- **결과**: 키워드 추출, TF-IDF 벡터화
- **다음 단계**: 덴드로그램, BERTopic에서 사용

### 2단계: 덴드로그램 시각화
- **역할**: 데이터의 계층적 구조 파악
- **결과**: 문서 간 유사도 시각화
- **용도**: 클러스터 수 결정 참고, 데이터 구조 이해

### 3단계: BERTopic 클러스터링
- **역할**: 의미 기반 토픽 자동 발견
- **결과**: 문서별 토픽 할당, 토픽별 대표 키워드
- **특징**: 토픽 수 자동 결정, 노이즈 처리

### 4단계: 감정분석
- **역할**: 각 문서의 감정 분류
- **결과**: 긍정/부정 레이블 및 확률
- **모델**: KcELECTRA-base-v2022 (한국어 최적화)

### 5단계: CAM 기회영역 시각화
- **역할**: 토픽의 중요도와 만족도 분석
- **결과**: 기회영역 액션맵 (Importance vs Satisfaction)
- **용도**: 개선 우선순위 결정

---

## ⚙️ 모델 정보

### 감정분석 모델: `beomi/KcELECTRA-base-v2022`
- **타입**: ELECTRA 기반 한국어 언어 모델
- **용도**: 시퀀스 분류 (Sequence Classification)
- **태스크**: 감정분석 (2-class: 긍정/부정)
- **확인**: https://huggingface.co/beomi/KcELECTRA-base-v2022
- **적합성**: ✅ 한국어 감정분석에 적합

### 토픽 모델링 임베딩: `jhgan/ko-sroberta-multitask`
- **타입**: SentenceTransformer 한국어 모델
- **용도**: 문서 임베딩 생성
- **특징**: 멀티태스크 학습으로 다양한 태스크에 적합
- **대안**: `jhgan/ko-sbert-nli` (NLI 전용)

---

## 💡 실행 팁

1. **첫 실행 시**: 각 단계를 순서대로 실행하여 결과를 확인하세요.
2. **대용량 데이터**: 
   - 덴드로그램은 `--max_docs` 옵션으로 샘플링
   - BERTopic은 배치 처리로 자동 최적화
3. **GPU 사용**: 
   - 감정분석과 BERTopic 임베딩은 GPU가 있으면 자동 사용
   - CPU만 있어도 실행 가능 (속도는 느림)
4. **결과 확인**: 각 단계의 CSV 파일을 Excel에서 열어 확인 가능

---

## 📁 출력 파일 구조

```
output/
├── 형태소분석_결과.csv
├── TFIDF_상위특성.csv
├── 단어빈도.csv
├── tfidf_matrix.pkl
├── 덴드로그램.png
├── 문서별_토픽할당.csv
├── 토픽요약정보.csv
├── 감정분석_결과.csv
├── 기회영역_분석.csv
└── 기회영역_분석_plot.png
```

---

## 🔍 문제 해결

### 모델 다운로드 오류
- 인터넷 연결 확인
- HuggingFace 토큰 필요 시 설정

### 메모리 부족
- 배치 크기 줄이기 (`--batch_size` 옵션)
- 문서 수 제한 (`--max_docs` 옵션)

### 한글 깨짐
- 모든 CSV는 `utf-8-sig` 인코딩으로 저장되어 Excel에서 정상 표시

